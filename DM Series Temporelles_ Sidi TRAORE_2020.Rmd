---
title: " DM de Series Temporelles"
date: "`r Sys.Date()`"
author: "Sidi TRAORE"
output:
  rmdformats::readthedown:
    highlight: kate
---


```{r setup, include=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=FALSE,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

<style>
body {
text-align: justify}
</style>


```{r library , echo=FALSE, message = FALSE, warning = FALSE, tidy=TRUE}

library(forecast)
library(caschrono)
library(dygraphs)
library(dplyr)
library(tseries)
library(vars)
library(fGarch)
library(lattice)
library(quantmod)
library(latex2exp)
library(Metrics)
```

# Exercice 1 : Actions d'Intel 
## Introduction
Dans cette partie, nous allons modéliser la  série $rtn$ (dans le fichier m-intc7303.txt). Cette série financière désigne les variations relatives mensuelles de
l’action Intel entre janvier 1973 et décembre 2003. La série $rtn$ semble avoir des effets saisonnaliers qui croissent avec le temps, on donc un modèle multiplicatif. Pour rendre la série additive, nous allons utiliser une transformation logarithmique. Ainsi on obtient le rendement mensuel de
ce cours d’action $logrtnt$  : 

$$\forall t \in [|1;372|] \quad logrtn_t = ln (1 + rtn_t)$$

```{r , echo=FALSE }

m_intc7303 <- read.csv("D:/ENSAI/3A/COURS/Time Series/TP_2/Donnees/m-intc7303.txt", sep="")
rtn <- m_intc7303$rtn

rtn <- ts(rtn,  start = c(1973,1), end = c(2003,12), frequency = 12)

#length(rtn)


#------- 0 Calul du Log
logrtn <-  log(1 + rtn)
logrtn_2 <- logrtn^2

#dygraph(rtn,xlab="Time",ylab="rtn") %>% 
#  dyRangeSelector()

dygraph(logrtn,xlab="Time",ylab="logrtn") %>% 
  dyRangeSelector()

#dygraph(logrtn_2,xlab="Time",ylab="logrtn2") %>% 
#  dyRangeSelector()

```
La représentation graphique du rendement mensuel du cours d'actions intel ($logrtnt$) ne présente pas de tendance, on remarque que les valeurs de la série fluctuent autour de 0. On remarque aussi 2 périodes de grandes volatilités. Ces volatililtés sont  dûes à des crises économiques qui ont provoqué une euphorie sur les marchés financiers. En effet la 1ère période de volatilité entre 1973 et 1974 résulte de la crise pétolière de 1973 encore appelé [premier choc prétolier](https://fr.wikipedia.org/wiki/Premier_choc_p%C3%A9trolier). La seconde période de volatilité apparu dans les années 2000 s'explique  par la grande
[récession du début des années 2000](https://fr.wikipedia.org/wiki/R%C3%A9cession_du_d%C3%A9but_des_ann%C3%A9es_2000). Cette crise financière a touché toutes les grandes économies du mondes et provoqué un effondrement du marché boursier. Ainsi, les indices comme le NASDAQ et le DOWJONES ont atteint niveau de décroissance record.



## 1. Teste de blancheur de $logrtnt$ et $logrtnt^2$

En rappelle, il existe trois notions de bruit blancs à savoir le bruit blanc fort, le bruit blanc gaussien et le bruit blanc faible. Nous nous intéressons spécialement à cette notion de bruit blanc faible.

Un processus $Y_t$ est bruit blanc (faible) si : 

$\forall t \in \mathbb{Z} :$  
1. $E(Y_t)$ = 0  
2. $E(Y_t^2) = \sigma^2$   
3  $Cov(Y_t, Y_{t'}) = 0$  


```{r , echo=FALSE }
par(mfrow = c(1,2))

acf(logrtn, ylim= c(-1,1) ,lag.max = 36 , main = TeX("$logrtnt$"))
# Abscence d'auto corrélation significative ce qui est en adéquation avec le test

acf(logrtn_2, ylim= c(-1,1) ,lag.max = 36, main = TeX("$logrtn^2$"))
# Présence d'autocorrélations significatives
par(mfrow = c(1,1))

```


L'ACF de $logrtnt$ ne décroît pas lentement vers 0, la série semble stationnaire. Aussi, elle ne montre aucun pic significatif (aucune autocorrelation significative), le processus semble être un bruit blanc. Pour nous en convaincre, nous réalisons le test de "Ljung-Box" (cf - annexe 1).
En considérant différentes valeurs de retards de la série (nlag) on trouve des
p-value > 5%, on en déduit que le rendement des actions Intel ($logrtn$) est bruit blanc.  

L'ACF de $logrtnt^2$ présente quelques pics significatifs. $logrtnt^2$ ne semble pas être donc un bruit blanc. Avec des p-valeurs < 5% pour différentes valeurs de retard considérées, le test de "Ljung-Box" nous permet de rejetter l'hypothèse que $logrtnt^2$ est un bruit blanc.

**Conclusion partielle : ** Le processus $logrtn$ est un bruit blanc tant dis que $logrtn^2$ ne l'est pas. 
A condition que $logrtn^2$ soit stationnaire, on peut modéliser $logrtn$ par un processus GARCH en identifiant un ARMA sur le processus  $logrtn^2$.

```{r , echo=FALSE }

caschrono :: Box.test.2(logrtn, nlag = c(6,12,18,24,30,36), type = "Ljung-Box", decim = 3)
# p_value > 5% donc on ne peut pas rejetter l'hypothèse de la blancheur des résidus
# on a un BB

```


```{r , echo=FALSE }
caschrono :: Box.test.2(logrtn_2, nlag = c(6,12,18,24,30,36) , type = "Ljung-Box", decim = 3)
# p_value < 5% On rejette la blancheur du résidu 

```


## 2. Identifier un(des) modèle(s) ARMA sur la série $logrtn^2$



```{r , echo=FALSE, include= FALSE }
#------- 2 Idenfier un modèle ARMA sur logrtn_2 :
dygraph(logrtn_2,xlab="Time",ylab= "logrtn2") %>% 
  dyRangeSelector()

```


```{r , echo=FALSE }
# Stationnarisation
#acf(logrtn_2, ylim= c(-1,1) ,lag.max = 36)
# faibles autocorélations décroissante vers 0

par(mfrow = c(1,2))
acf(logrtn_2, ylim= c(-1,1) ,lag.max = 36)
# 3 pics significatis MA(3) ?
pacf(logrtn_2, ylim= c(-1,1) ,lag.max = 36)
# 3 Pics significatifs AR(3)
par(mfrow = c(1,1))

```
L' ACF présente de faibles autocorélations décroissantes vers 0. Le processus semble stationnaire. Pour s'en convaincre, nous allons effectuer le test augmenté de Dickey Fuller (ADF) (cf Annexe 2).


```{r , echo=FALSE }

# ?adf.test()
adf.test(logrtn_2) # p_value <  0.01 < 5%

# On rejette l'hpohèse de présence de racine unitaire

# La série est stationnaire

```
La p-value =  0.01 < 5%, on rejette l'hypothèse de présence de racine unitaire. 
On peut donc dire que $logrtnt^2$ est stationnaire.

Pour identifier l'ordre $p$ et $q$, de notre $ARMA(p,q)$ regardons l'ACF et le PACF.

```{r , echo=FALSE, include = FALSE }
par(mfrow = c(1,2))
acf(logrtn_2, ylim= c(-1,1) ,lag.max = 36)
# 3 pics significatis MA(3) ?
pacf(logrtn_2, ylim= c(-1,1) ,lag.max = 36)
# 3 Pics significatifs AR(3)
par(mfrow = c(1,1))

```
L'ACF et le PACf nous indique 3 pics significatifs, il semble que p = q = 3. On a à priori un ARMA(3,3). Pour valider notre modèle, nous allons effectuer le test de student de significativité des paramètres sur les processus ARMA(3,3), ARMA(2,2), ARMA (2,1) et ARMA(1,1).


```{r , echo=FALSE }
# Modélisation 
model0 <- Arima(logrtn_2, order = c(3,0,3))
t_stat(model0) # le modèle a des paramètres non significatifs on teste un autre

model1 <- Arima(logrtn_2, order = c(2,0,2))
t_stat(model1)

# Validation du modèle 
t_stat(model1) # le modèle a des paramètres non significtifs on teste un autre

model2 <- Arima(logrtn_2, order = c(1,0,2))
t_stat(model2)# Des paramètres non significatifs on teste un autre

model4 <- Arima(logrtn_2, order = c(1,0,1))
t_stat(model4)

```

Les résultats de ces tests indiquent que seul le processus ARMA(1,1) a tous ses paramètres significatifs (avec des p-valeurs<5%). 

**Conclusions** : On identifie donc le processus ARMA(1,1) pour le processus $logrtn^2$. 



$$ (I - \phi_1 B) Y_t^2  =  (I - \theta_1 B) \epsilon_t$$

On peut donc modéliser le rendement des actions d'Intel $logrtn$ par un processus $GARCH(1,1)$.


## 3. Modéliser sous forme de processus GARCH la série $logrtn$

```{r , message = FALSE, warning = FALSE, tidy=TRUE}

model_garch1 <- garchFit(formula = ~ garch(1, 1), data = logrtn, trace = FALSE)


summary(model_garch1)# tous les paramètres sont significatifs

# blancheur des résidus
# On peut accepter l'hypothèse de blancheur des résidus
# On peut accepter l'hypothèse de blancheur des résidus au carré
# On ne peut accepter l'hypothèse de normalité des résidus Test de Shapiro-Wilk (p_value = 2.471139e-07)

# Donc on a fait du quasi maximum de vraissemblance

```

Le teste de student de significativité des paramètres du processus GARCH(1,1), nous indique que tous les paramètres sont significatifs au seuil de 5%.
Aussi les résidus et le carré des résidus sont bruit blanc (p_value du test de "Ljung-Box" > 5%).
Enfin, le test d'hétéroscédasticité "Arch" permet de rejetter l'hypothèse de présence d'hétéroscédascité conditionnelle dans nos résidus (p_value = 0.6741288 > 5%) .




**Conclusions** : On a obtenu un modèle GARCH(1,1), avec tous les paramètres significatifs. Et aussi des résidus bruits blancs non hétéroscédastiques. Et des résidus au carré bruit blancs.

$$\forall t \in \mathbb{Z} : logrtn_t = \sigma_t \epsilon_t, \\
\sigma_t^2 = W + \alpha_1 logrtn_{t-1}^2 + \beta_1 \sigma_{t-1}^2
$$

Avec $W$ = 0.0163276, $\alpha_1$ = 0.0802716  et  $\beta_1$ = 0.8553014



# Exercice 2 : S&P 

## Introduction
Dans cette partie, nous analysons le cours mensuel de l'indice boursier S&P 500 (standard & Poors) de Novembre 1970 à Novembre 2020. 
Le S&P 500 est l'indice phare de la bourse américaine. 
Il regroupe les 500 plus grandes entreprises cotées sur le 
NYSE ou le NASDAQ et est donc plus représentatif de l'économie
 Américaine que le Dow Jones qui est seulement basé sur 30
 valeurs.Il englobe tous les secteurs d'activités. 
Le nombre important d'actions qui le composent lui permet de 
couvrir une grande part du marché boursier Américain. En terme 
de capitalisation boursière, il représente 80% des sociétés 
cotées à Wall Street d'après [Yahoo finance](https://fr.finance.yahoo.com/quote/%5EGSPC/options?p=%5EGSPC).
 
L'intérêt de la modélisation d'une telle série est de pouvoir prévoir l'évolution du marché financier des USA. En effet, en anticipant le comportement du marché, on peut dévelloper des stratégies de trading "gagnants".
 
Le S&P étant une série financière, nous allons considérer le logarithme du rendement de la série S&P définit comme suit : 
 
 $$\forall t \space  \in\space \space [|1, 601|], \space logrsp = log(\frac{sp_t}{sp_{t-1}})  $$

## Blancheur et stationnarité des processus

```{r , echo=FALSE }
######################
GSPC <- read.csv("D:/ENSAI/3A/COURS/Time Series/DM/DM_1/^GSPC.csv")
sp <- GSPC
logrsp = diff(log(sp$Close))

series <- ts(sp$Close, start = c(1970,11), end = c(2020,11), frequency = 12)
logrsp = diff(log(series))
logrsp_2 = logrsp^2

```


```{r , echo=FALSE }
#plot(series)

dygraph(logrsp,xlab="Time",ylab="logrsp") %>% 
  dyRangeSelector()
#plot(logrsp_2)

```

La représentation graphique de l'indice S&P ne présente pas de tendance. Les valeurs de la série oscillent autour de 0. En plus l'ACF ne présente aune autocorrelation significative au seuil de 5%. Le rendement de l'indice S&P (logrsp) semble être un bruit blanc. 

```{r , echo=FALSE }
acf(logrsp , ylim = c(-1,1), lag.max = 36)
```
Pour nous en convaincre, nous effectuons un test de bruit blanc de "Ljung-Box".
```{r , echo=FALSE }
caschrono :: Box.test.2(logrsp, nlag = c(6,12,18,24,30,36), type = "Ljung-Box", decim = 3)
```


Avec des p-value > 5% pour différents retards considérés, on en déduit que le processus logrsp est un Bruit blanc.



```{r , echo=FALSE }
par(mfrow = c(1,2))
acf(logrsp_2, ylim = c(-1,1), lag.max = 36)
pacf(logrsp_2, ylim = c(-1,1), lag.max = 36)
par(mfrow = c(1,1))
```

l'ACF de $logrsp^2$, présente un pic significatif. Ce processus n'est donc pas un bruit blanc. Avec des p-value < 5%, le test de "Ljung-Box" nous permet de conforter ce constat.

```{r , echo=FALSE }
caschrono :: Box.test.2(logrsp_2, nlag = c(6,12,18,24,30,36), type = "Ljung-Box", decim = 3)
#adf.test(logrsp_2)

```


**Conclusion partielle : ** Le processus $logrsp$ est un bruit blanc tandis que $logrsp^2$ ne l'est pas.  
Avec une p-valeur = 0.01, le test augmenté de Dickey-Fuller nous permet nous permet de réjeter l'hypothèse de présence de racine unitaire dans le processus $logrsp^2$. Ce processus est donc stationnaire. Ainsi on peut modéliser $logrsp$ par un processus GARCH en identifiant un ARMA sur le processus  $logrsp^2$.  




## Identification du Processus ARMA

Comme vu plus haut le graphe des ACF et des PACF présente un seul pic significatif. On identifie donc un processus $ARMA(1,1)$

```{r , echo=FALSE }
print("Significativité des coefficients : ARMA(1,1)")
model1 <- auto.arima(logrsp_2)
t_stat(model1)

```



```{r , echo=FALSE }
print("Blancher des résidus")
Box.test.2(model1$residuals,  nlag = c(6,12,18,24,30,36), type = "Ljung-Box", decim = 3)
```

Le test de student nous montre que tous les coefficients du modèle ARMA(1,1) sont significatifs. En plus le test de "Ljung-Box" nous montre que les résidus de ce processus sont bruits blancs. 

**Conclusion partielle: **  Le modèle ARMA(1,1) conçu sur la série $logrsp^2$ est statistiquement valide. On peut donc modéliser le rendement mensuel de l'indice S&P par un processus GARCH(1,1).  


## Modélisation d'un processus GARCH

```{r , echo=FALSE }
# garch
model_garch1 <- garchFit(formula = ~ garch(1, 1), data = logrsp, trace = FALSE)

summary(model_garch1)# tous les paramètres sont significatifs # tous les test concluants

```

Tous les coefficients du modèle GARH(1,1) sont significatifs. En plus, le test de blancheur des résidus indique qu'ils sont bruits blancs (p-value > 5%). Ils ne sont pas hétéroscédastiques (p-value = 0.9211063 > 5% Test Arch). Aussi, les résidus au carré sont bruits blancs (p-value > 5 %).


**Conclusion : ** Le processus GARCH(1,1) est donc statistiquement valide. Le rendement mensuel de l'indice S&P peut être modéliser par l'équation suivante. 

$$\forall t \in \mathbb{Z} : logrsp_t = \sigma_t \epsilon_t, \\
\sigma_t^2 = W + \phi_1 logrsp_{t-1}^2 + \beta_1 \sigma_{t-1}^2
$$

# Exercice 3 : Modélisation VAR des PIB

## Introduction 

Dans cette partie, nous allons analyser  les PIB trimestriels du Royaume-Uni, du Canada et des USA, entre 1980 et 2011. Dans une première partie, nous analysons ces séries individuellement avec des modèles ARIMA. Et dans une seconde partie, nous les analysons en considérant un vecteur de séries temporelles. L'idée d'un tel model est qu'il permet de tenir compte des relations entre les séries afin d'avoir une meilleure prévision.

## 1 Modélisation des séries
### a. Modélisation ARMA

```{r , echo=FALSE }

#============================
#------- 1 - Exercice 1
#============================
PIB <- read.csv("D:/ENSAI/3A/COURS/Time Series/TP_3/q-gdp-ukcaus.txt", sep="")
UK <- ts(PIB$uk, start = c(1980,1), end = c(2011,2) , frequency = 4)
CA <- ts(PIB$ca, start = c(1980,1), end = c(2011,2) , frequency = 4)
US <- ts(PIB$us, start = c(1980,1), end = c(2011,2) , frequency = 4)

#dygraph(UK, main = "PIB UK") %>%
#  dySeries("V1", label = "PIB") %>%
#  dyOptions(maxNumberWidth = 10) %>%
#  dyRangeSelector()

```


```{r , echo=FALSE }

par(mfrow = c(2,3))

plot(UK, main = "PIB UK")
plot(CA, main = "PIB CA")
plot(US, main = "PIB US")

# Nous passons à une transformation log() du taux de croissance
diff_UK = diff(log(PIB$uk))*100
diff_CA = diff(log(PIB$ca))*100
diff_US = diff(log(PIB$us))*100

plot.ts(diff_UK, main = "PIB UK", ylim = c(-2,2))
plot.ts(diff_CA, main = "PIB CA", ylim = c(-2,2))
plot.ts(diff_US, main = "PIB US",  ylim = c(-2,2))

par(mfrow = c(1,1))

```

Les graphiques représentant les PIB de la Grande Bretagne, du Canada et des Etats-Unis, présentent une tendance générale croissante de 1980 à 2011. Ce pendant cette évolution est marqué par deux périodes de légères décroissance de 1990 à 1991 et de 2007 à 2008. La première décroissance est dûe à la [récession du début des années 1990](https://fr.wikipedia.org/wiki/R%C3%A9cession_du_d%C3%A9but_des_ann%C3%A9es_1990) qui a été une crisé économique mondiale résultant de l'effondrement du Dow Jones Industrial. La deuxième décroissance est dûe à la [crise des subprimes](https://fr.wikipedia.org/wiki/Crise_des_subprimes), une crise financière qui a touché le secteur des prêts hypothécaires dans le monde entier.  
Etant donné que ces séries présentent une tendance, elle ne peuvent pas être stationnaire. Pour stationnariser ces processus, nous les avons différencié.  
Le gaphique des PIB différencié montre que les valeurs oscillent autour de 0. Elle semble donc stationnaire.


```{r , echo=FALSE }
par(mfrow = c(2,3))

acf(x = diff_UK, ylim = c(-1,1))
acf(x = diff_CA, ylim = c(-1,1))
acf(x = diff_US, ylim = c(-1,1))

# Tous les autocorrélations décroissent exponentiellement vers 0. 
# Les différentes séries semblent stationnaires.


#------------------- 2  Ordre P et Q de ARMA(p,q) :

# Les ACF présentent une décroissance exponentielle vers 0, 
# La partie MA est nulle, q = 0
pacf(x = diff_UK, ylim = c(-1,1))
pacf(x = diff_CA, ylim = c(-1,1))
pacf(x = diff_US, ylim = c(-1,1))
par(mfrow = c(1,1))

# Les PACF présentent un seul pic significatif
# On p = 1

# CONCLUSION : On semble avoir des ARIMA(1,0,0). sur les séries log différenciés
  #Donc des ARIMA(1,1,0), pour les log(xt) des séries

```

Le graphe des ACF (des séries différenciées) décroît (exponnetiellement) vers 0. Cela nous conforte dans notre conjecture. Enfin, le test augmenté de Dickey-Fuller nous permet de conclure que les séries différenciées sont stationnaires.On a donc un processus Intégré d'ordre 1 : $I(1)$.

```{r , echo=FALSE, include= FALSE }
#------------------- 1 Tester la stationnarité :

adf.test(x = diff_UK)#P-value <1%  On rejette l'hpohèse de présence de racine unitaire
adf.test(x = diff_CA) #P-value <1%  On rejette l'hpohèse de présence de racine unitaire
adf.test(x = diff_US) #P-value <1%  On rejette l'hpohèse de présence de racine unitaire

#Les séries sont stationnaires

```

Comme vu précédamment, le graphique des ACF présente une décroissance exponentielle vers 0. On en déduit que l'ordre q = 0 de la partie MA. Alors que le graphique des PACF des trois séries présente un seul pic significatif. On en déduit que l'ordre p = 1 pour la partie AR.

**Conclusison : ** On identifie des processus $ARIMA(1,1,0)$. Par ailleurs, à travers une procédure automatique "$auto.arima()$", le processus $ARIMA(1,1,0)$ est celui qui minimiser le "BIC".

$$ (I - \phi_{11} B)(I -  B)PIB.UK =  (I - \theta_{11} B) \epsilon_t$$
$$ (I - \phi_{21} B)(I -  B)PIB.CA =  (I - \theta_{21} B) \epsilon_t$$
$$ (I - \phi_{31} B)(I -  B)PIB.US =  (I - \theta_{31} B) \epsilon_t$$




```{r , echo=FALSE, include= FALSE }
#------------------- 2 bis  Ordre P et Q de ARMA(p,q) procédure automatique :
auto.arima(log(PIB$uk), ic = "bic")
auto.arima(log(PIB$ca), ic = "bic")# il suppose la présence de saisonnalité ce qui n'est pas le cas
auto.arima(log(PIB$us), ic = "bic")
# La procédure automatique suggère un ARIMA(1,1,0). 
# Donc nos modèles ARIMA(1,1,0) minimisent aussi le "bic"

```




```{r , echo=FALSE}

#------------------- 3 Modélisation
model_uk <-Arima(log(PIB$uk), order = c(1,1,0))
model_ca <-Arima(log(PIB$ca), order = c(1,1,0))
model_us <-Arima(log(PIB$us), order = c(1,1,0))

t_stat(model_uk)
t_stat(model_ca)
t_stat(model_us)

# Tous les paramètres sont significatifs


#------------------- 4 Validation tester la blancheur des résiuds
#------------------- Tester la blancheur des résidus:
Box.test.2(model_uk$residuals, nlag = c(4,8,12), type =  "Ljung-Box")
Box.test.2(model_ca$residuals, nlag = c(4,8,12), type =  "Ljung-Box")
Box.test.2(model_us$residuals, nlag = c(4,8,12), type =  "Ljung-Box")

# Les résidus sont BB : on accepte notre modèle ARIMA(1,1,0)
```
Les différents modèles ARIMA(1,1,0) ont tous des paramètres significatifs et des résidus bruits blancs. On peut donc valider ces modèles.  


Toutefois, on peut considérer une autre approche pour modéliser ces valeurs de PIB. En effet le PIB de ces trois pays peut être considéré comme un vecteur de PIB. Dans ce cas, on utilise un modèle VAR. L'utilisation d'un tel modèle serait intéressant si la connaissance du PIB d'un pays améliore la prédivision du PIB d'un autre; c'est à dire qu'il y a de la causalité au sens de Granger.  

Le test de causalité au sens de Granger indique qu'il y a de la causalité. Par exemple,  La connaissance du PIB des US et UK améliore la Prévision de celui du Canada. On a donc intérêt à considérer un vecteur auto-régressif de PIB (VAR).
Naturellement cette présence de causalité peut s'expliquer par la proximité géographique des Etats-Unis et du Canada et aussi par les relations commerciales importantes que les USA et le Royaume-Uni entretiennent avec le Canada. En effet, les Etats-Unis et le Royaume-Uni sont les deux plus grands partenaires commerciaux du Canada [(Economie du Canada)](https://fr.wikipedia.org/wiki/%C3%89conomie_du_Canada). En outre notons que ces relations ne sont pas réciproques. Par exemple, le Canada n'est pas un partenaire commercial incontournable pour les USA. Ainsi, la connaissance du PIB du Canada n'améliore pas la prévision de celui des Etats-Unis comme indique le test de causalité de granger (p-valeur  = 0.5648). 





```{r , echo=FALSE }


#============================
#------- 2 - Modélisation VAR
#============================

#series <- ts(diff(log(PIB[, -(1:2)]))*100, start = c(1980,1), end = c(2011,4) , frequency = 4) # Convert to time series format
series<-cbind(diff_UK,diff_CA,diff_US)
series <- ts(series ,start = c(1980,1), end = c(2011,4) , frequency = 4)
#plot.ts(series) # Plot the series

#---------------- Gagne t_on en utilisant un modèle VAR ?
grangertest(diff_CA ~ diff_UK, order = 1, data = series)
grangertest(diff_CA ~ diff_US, order = 1, data = series)

#grangertest(diff_UK ~ diff_CA, order = 1, data = series)


#grangertest(diff_US ~ diff_UK, order = 3, data = series)

#grangertest(diff_US ~ diff_CA, data = series)

# On des causalités au sens de Granger
# La connaissance des PIB des US et UK améliore la Prévision de celle de CA



```




### b. Modélisation VAR


```{r , echo=FALSE }
#------------------Estimer un Var
var.1 <- VAR(series, 1) # Estimate the model
critrere <- VARselect(series, lag.max = 15)
d<- as.data.frame(critrere)
td <- t(d)
td <- as.data.frame(td)
td<- td[-1,]
plot(td$`SC(n)`, type = "o", main = " Critere d'information VAR(P)", ylim = c(-3.8,0.1), ylab = "Valeurs IC", xlab = "p")
lines(td$`HQ(n)`, type = "o", col = "blue")
lines(td$`AIC(n)`, type = "o", col = "red")
legend("topleft", legend=c("BIC", "HQ", "AIC"),
       col=c( "black", "blue", "red"), lty=1:2, cex=0.8)

serial.test(var.1, lags.pt=10, type="PT.asymptotic")


```
Le BIC, le HQ sont minimisés pour une valeur de p = 1. On choisit un modèle VAR(1). Et les résidus de ce modèle sont bruits blancs (p-value = 0.225).

Ce pendant ce modèle a t-il une meilleure capacité prédictive que les 3 modèles ARIMA ? Pour répondre à cette question nous évaluons le pouvoir prédictif de ces deux approches sur les 4 dernières observations (nos données de validation), les modèles étant construits sur le reste des observations. Nous utilisons l'écart absolu moyen (MAE) pour challenger ces approches.

$$MAE = \Sigma_{i=1}^n | \hat{Y_i} - Y_i |$$





```{r , echo=FALSE, include= FALSE }
# VAR 2 ?

#criteria <- as.data.frame(t(var$criteria))

var.aic <- VAR(series, type = "none", lag.max = 10, ic = "AIC")
summary(var.aic)
```

## 2 Prévisions des modèles

Les graphiques ci-dessous présentent la prévisions des PIB du Royaume-Uni (UK), du Canada(CA) et des Etats-Unis (US) entre 2010 et 2011. L'analyse de ces graphiques montre que pour les PIB du Royaume-Uni et du Canada, les prévisions réalisés avec le processus VAR sont plus proches des valeurs observées que celles réalisées avec les processus ARIMA. Tandis que pour le PIB des USA, les prévions réalisées avec le processus VAR s'éloignent dratisquement des valeurs observées. On en déduit que pour la prévision du PIB du Royaume-Uni et du Canada, le processus VAR a une meilleure capacité prédictive que les modèles ARIMA. Mais pour la prévision du PIB des USA, les modèles ARIMA ont une meilleure capacité prédictive que le processus VAR.

```{r , echo=FALSE, include= FALSE }

UK <- ts(PIB$uk, start = c(1980,1), end = c(2011,2) , frequency = 4)
CA <- ts(PIB$ca, start = c(1980,1), end = c(2011,2) , frequency = 4)
US <- ts(PIB$us, start = c(1980,1), end = c(2011,2) , frequency = 4)



t_UK = window(UK,  start =  c(1980,1), end=c(2010,2))
t_CA = window(CA,  start =  c(1980,1), end=c(2010,2))
t_US = window(US,  start =  c(1980,1), end=c(2010,2))

series<-cbind(log(PIB$uk),log(PIB$ca),log(PIB$us))
series <- ts(series ,start = c(1980,1), end = c(2011,4) , frequency = 4)

train_series = window(series,  start =  c(1980,1), end=c(2010,2))
colnames(train_series) <- paste(c("UK", "CA", "US"))



model_uk <-Arima(train_series[,1], order = c(1,1,0))
model_ca <-Arima(train_series[,2], order = c(1,1,0))
model_us <-Arima(train_series[,3], order = c(1,1,0))

autoplot(forecast(model_uk, h = 4))
autoplot(forecast(model_ca, h = 4))
autoplot(forecast(model_us, h = 4))



uk = forecast(model_uk, h = 4)
uk_pred = exp(uk$mean)

ca = forecast(model_ca, h = 4)
ca_pred = exp(ca$mean)

us = forecast(model_us, h = 4)
us_pred = exp(us$mean)


test_series = window(series, start=c(2010,3), end=c(2011,2))
colnames(test_series) <- paste(c("UK", "CA", "US"))

mae_uk = mae(exp(test_series[,1]), uk_pred)
mae_ca = mae(exp(test_series[,2]), ca_pred)
mae_us = mae(exp(test_series[,3]), us_pred)

MAE_Totale_ARIMA = (mae_uk + mae_ca + mae_us)/3


arima_mse_uk = mean(sqrt((exp(test_series[,1]) - uk_pred)^2))
arima_mse_ca = mean(sqrt((exp(test_series[,2]) - ca_pred)^2))
arima_mse_us = mean(sqrt((exp(test_series[,3]) - us_pred)^2))

arima_MSE_Totale = (arima_mse_uk + arima_mse_ca + arima_mse_us)/3



VAR_model = VAR(train_series, 1)

autoplot(forecast(VAR_model, 4))

Var_forecast = predict(VAR_model, n.ahead = 4)

Var_forecast_val = Var_forecast$fcst

var_uk = Var_forecast_val$UK
var_ca = Var_forecast_val$CA
var_us = Var_forecast_val$US

mae_uk_var = mae(exp(test_series[,1]), exp(var_uk[,1]))
mae_ca_var = mae(exp(test_series[,2]), exp(var_ca[,1]))
mae_us_var = mae(exp(test_series[,3]), exp(var_us[,1]))

MAE_Totale_var = (mae_uk_var + mae_ca_var + mae_us_var)/30




var_mse_uk = mean(sqrt((exp(test_series[,1]) - exp(var_uk[,1]))^2))
var_mse_ca = mean(sqrt((exp(test_series[,2]) - exp(var_ca[,1]))^2))
var_mse_us = mean(sqrt((exp(test_series[,3]) - exp(var_us[,1]))^2))


#var_MSE  = sqrm(exp(test_series[,3]), us_pred)

Var_MSE_Totale = (var_mse_uk + var_mse_ca + var_mse_us)/30

#legend("topleft", legend=c("UK", "CA", "US"),
#       col=c( "black", "blue", "red"), lty=1:2, cex=0.8)

```

```{r , echo=FALSE }
par(mfrow = c(1,3))

compare_uk = cbind(exp(test_series[,1]), uk_pred, exp(var_uk[,1]))

colnames(compare_uk) <- paste(c("Observée", "Arima", "VAR"))
dygraph(compare_uk,xlab="Time", main = " Prévisions UK" ) %>% 
    dyRangeSelector()


compare_ca = cbind(exp(test_series[,2]), ca_pred, exp(var_ca[,1]))

#colnames(compare_ca) <- paste(c("Observée", "Arima", "VAR"))
#dygraph(compare_ca,xlab="Time",main =" Prévisions CA") %>% 
#    dyRangeSelector()

compare_us = cbind(exp(test_series[,3]), us_pred, exp(var_us[,1]))

colnames(compare_us) <- paste(c("Observée", "Arima", "VAR"))
dygraph(compare_us,xlab="Time",main =" Prévisions US") %>% 
    dyRangeSelector()

par(mfrow = c(1,1))

```



## 3 Performances à posteriori

```{r , echo=FALSE }


MAE_Totale_ARIMA = (mae_uk + mae_ca + mae_us)/3
MAE_Totale_var = (mae_uk_var + mae_ca_var + mae_us_var)/3
cat("MAE ARIMA =  ", MAE_Totale_ARIMA, " ET ", "MAE VAR =  ", MAE_Totale_var)

#cat("MSE ARIMA =  ", arima_MSE_Totale,  "VS", "MSE VAR =  ", Var_MSE_Totale)

```



En moyenne le prévisions du modèle VAR(1) s'écartent beaucoup plus des valeurs observées que celles des processus ARIMA(1,1,0). Donc Les modèles ARIMA ont une meilleure capacité prédictive que le processus VAR(1). Ce résultat s'explique par l'écart important du processus VAR(1) pour la prévision du PIB des USA.

**Conclusion : ** pour modéliser les PIB de la Grande Bretange, du Canada et des Etats-Unis, on a beaucoup plus intérêt à utiliser trois processus ARIMA(1,1,0) qu'un processus VAR(1).



```{r , echo=FALSE }

```


# Exercice 4 Implémentation des modèles VAR, SVAR et SVEC.  

Cette partie est réalisée par : Sidi TRAORE et Brice Camel TIFA

## Introduction  

Depuis les années 1980 suite aux critiques de Sims relativement à l'hypothèse d'exongénéité des variables dans la modélisation de phénomènes macro-économiques, l'analyse des séries temporelles multivarirées dans le contexe des VAR (Vector Auto-Regressive) a beaucoup évolué et est devenu un instrument standard en économétrie. En effet, des tests statistisques sont utilisées pour déterminer l'inter-dépendance et la relation dynamique dans les variables. Cette méthodologie a été enrichie avec l'incorporation des informations à priori non statisques.  

Les modèles VAR expliquent les variables endogènes uniquement par leur propre histoire, en dehors des régresseurs déterministes. En revanche, les modèles vectoriels autorégressifs structurels (SVAR) permettent l'explicitation la modélisation de l'interdépendance contemporaine entre les variables. Il tentent donc de contourner les défauts des modèles VAR. Cependant, qu'il s'agisse des modèles VAR ou SVAR, la stationarité de chaque variable est un prérequis à la modélisation.
 
Engle et Granger (1987) ont doté les économétriciens avec un outil puissant pour modéliser et tester les relations économiques, à savoir le concept de co-intégration. Aujourd'hui, ces branches de la recherche sont unifiées sous la forme des modèles de correction vectorielle des erreurs (VECM) et de correction vectorielle structurelle des erreurs (SVEC).  

Dans ce travail, reproduirons les travaux de bernhard pfaff. Concrètement, nous présenterons les principaux concepts des modèles VAR, SVAR, VECM, SVEC et la mettrons en oeuvre ces derniers sur un jeu de données relatifs à la macroéconomie canadiènne.

### 1 Modèles VAR 
#### 1.1 Cadre théorique

Un processus Vecteur Auto-Regressif d'ordre p, noté VAR(p) est spécifié comme suit : 

\begin{equation}
y_t = A_1y_{t-1} + ... + A_p y_{t-p} + u_t
\end{equation}

Où les $A_i$, pour ${i = 1, ..., p}$, sont des coefficients d'une matrice de dimension $(K \times K)$ et les résidus $u_t$ sont bruits blancs. C'est à dire : 

$$\mathbb{E}(u_t) = 0 \quad \mathrm{et} \quad \mathbb{E}(u_tu_t^T) = \Sigma_u$$ 
La matrice de variance-covariance des érreurs, $\Sigma_u$, est supposée indépendante du temps et définie positive.  

On peut réecrire le modèle VAR comme suit :  

$$y_t - A_1y_{t-1} - ... - A_p y_{t-p} = u_t  \\
(I_K - A_1z - ... A_pz^p)y_t =  u_t  \\
\Phi(z)y_t = u_t \space 
$$
Tout processus VAR(p) peut être reécrit sous forme d'un processus VAR(1) en utilisant les notations suivantes:

$$\xi_t = A \xi_{t-1} + v_t$$  
Avec :

$$\xi_t = 
\left(\begin{array}{c} 
y_t\\
.\\
.\\
.\\
y_{t-p+1}
\end{array}\right),
A =
\left(\begin{array}{ccccccc}
 A_1 & A_2  &.  &.  &.  & A_{p-1} &A_p  \\ 
 I &0  &.  &.  &.  &0  &0  \\
 0& I  & .  &.  & . &0  &0  \\
 .& . &.  &  &  & . &.  \\
 .& . &  &.  &  & . &.  \\
 .& . &  &  &.  & . &.  \\
 0& 0  &.  &.  &.  & I  &0 
\end{array}\right),
v_t =
\left(\begin{array}{c}
u_t\\
0\\
.\\
.\\
.\\
0
\end{array}\right)
$$


Avec $\xi_t$ et $v_t$ des vecteurs de dimension $(KP \times 1)$ et $A$ une matrice de 
dimension $(KP \times KP)$. 

Une caractéristique importante du processus VAR(p) est sa stabilité. Le processus $VAR(P)$ est stable si sa formulation VAR(1) est stable. Autrement dit, si toutes les valeurs propres  de $A$ sont de module est inférieur à 1.


#### 1.2 Implémentation 

Pour la mise en en application du modèle, les auteurs analysent les données du marché de travail Canadien entre le premier trimestre 1980 et le quatrième trimestre 2004 à travers quatre indicateurs économiques à savoir: la productivité du travail "prod", le taux d'emploi "e", le taux de chômage "u" et l'indice de salaire réel "rw".  Ainsi, on pose

$$y_t =
\left(\begin{array}{c} 
prod_t\\
e_t\\
u_t\\
rw_t
\end{array}\right)
$$
Les auteurs entament l'étude par une représentation graphique des séries.

```{r , echo=FALSE }
library("vars")
data("Canada")
plot(Canada, nc = 2, xlab = "")

```

Le graphique ci-dessus permet de remarquer une tendance croissante pour le taux d'emploi (e), la productivité (prod) et l'indice du salaire (rw). Tandis que le taux de chômage (u) ne présente pas de tendance. 

Point clé de la modélisation VAR, l'étude de la stationarité est ensuite mise en oeuvre. 

**Stationnarité : **  

La première étape pour les auteurs a consisté a effectué des test augmenté de Dickey-Fuller pour vérifier la stationnarité du processus VAR. 

```{r , echo=FALSE, include= FALSE }
adf1.prod <- summary(ur.df(Canada[, "prod"], type = "trend", lags = 2))
adf2.prod <- summary(ur.df(diff(Canada[, "prod"]), type = "drift", lags = 1))
adf1.prod
adf2.prod

adf1.e <- summary(ur.df(Canada[, "e"], type = "trend", lags = 2))
adf2.e <- summary(ur.df(diff(Canada[, "e"]), type = "drift", lags = 1))
adf1.e
adf2.e

adf1.rw <- summary(ur.df(Canada[, "rw"], type = "trend", lags = 2))
adf2.rw <- summary(ur.df(diff(Canada[, "rw"]), type = "drift", lags = 1))
adf1.rw
adf2.rw

adf1.U <- summary(ur.df(Canada[, "U"], type = "trend", lags = 2))
adf2.U <- summary(ur.df(diff(Canada[, "U"]), type = "drift", lags = 1))
adf1.U
adf2.U

```

Les résultats de ces tests montrent que le processus "prod" est intégré d'ordre 1. En effet, les séries brutes ne sont pas stationnaires en teandance tandis que les séries différenciées au premier ordre sont stationaires.

Les auteurs continue néanmoins la modélaisation VAR sur la série brute. Ils s'intéressent par la suite à l'ordre $p$ du modèle. Ils reprennent pour ce faire les travaux de Breitung et al. (2004).

**Sélection du modèle : ** 

Pour sélectionner le nombre de retard, les auteurs ont utilisé une procédure automatique, et recherché le nombre de retards qui minimise les critères d'informations AIC, FPE, HQ et SC.

```{r , echo=FALSE }
selection <- VARselect(Canada, lag.max = 8, type = "both")
selection$selection

```

Selon l'AIC et la FPE, le nombre optimal de retards est p = 3, le HQ indique p = 2 et le critère SC indique un nombre optimale de retard p = 1.  
Ils ont estimé pour les trois ordres de retards, un VAR comprenant une constante et une tendance comme régresseurs déterministes. Pour valider le modèle, ils ont considéré le taux d'empoi (e) et ont effectué des tests sur les résidus de ce processus.

$$e_t = e_{t-1} + u_{t-1} + r w_{t-1} + \epsilon_t$$
Pour $p=1$ par exemple, 

```{r , echo=FALSE, include= FALSE }
Canada <- Canada[, c("prod", "e", "U", "rw")]
p1ct <- VAR(Canada, p = 1, type = "both")
p1ct
```

**Validation / Tests sur les résidus : **

Les auteurs effectuent un diagnostic des résidus pour les trois modèles VAR, ce en se basant sur les tests d'autocorrélations, le test ARCH multivarié et le test de Juarque-Berra.

```{r , echo=FALSE }
plot(p1ct, names = "e")

```


```{r , echo=FALSE, include= FALSE }

ser11 <- serial.test(p1ct, lags.pt = 16, type = "PT.asymptotic")
ser11$serial
norm1 <- normality.test(p1ct)
norm1$jb.mul


```

Parmi les modèles considérés, les résidus du modèle VAR(1) sont bruits blancs (p-value =$0.606>5\%$, test de Portemanteau) et suivent une loi normale (p-value =  0.2708 pour le test de Jacque Berra). Par contre le test d'hétéroscédasticité d'Engle ne nous permet pas d'accepter l'hypothèse d'homoscédasticité des résidus pour le processus VAR(1) (p-value = 0.01606).  

Compte tenu des résultats des tests de diagnostic, les auteurs (Breitung et al.) ont conclu qu'une spécification VAR(1) pourrait être trop restrictive. Ils maintiennent toutefois les modèles VAR(2) et VAR(3) comme candidats au test de cointégration. 

Dans la suite, les auteurs estiment un modèle VECM dans lequel une tendance déterministe a été incluse. Avant de présenter ce modèle VECM, nous allons présenter le modèle SVAR.

### 2 Structural vector autoregressive models SVAR

Le modèle SVAR est la forme généralisée du modèle VAR(P). Il se définit comme suit : 

$$Ay_t = A_1^*y_{t-1} + ... + A_p^*y_{t-p} + B \epsilon_t$$
Pour la modélisation, les hypotèses suivantes sont formulées :  
1 - Les résidus structurels $\epsilon_t$ sont bruit blanc.
2 - Les coeffecients structurels sont différents de ceux du modèle VAR(p).  

La remarque que l'on peut faire sur la formulation de ce modèle est qu'elle est quasiment égale à celle d'un VAR quand $A=B=Id$ (abscence de corrélation temporelle ou d'effets simultanés entre les variables).

Un modèle SVAR peut être utilisé pour identifier les chocs et les retracer en utilisant l'IRA (Impulse Response Analysis) et/ou le FEVD (Forecast Error Variance Decomposition), ce en imposant des restrictions sur les matrices A et/ou B.  Les auteurs évoquent en effet deux avantages du modèle SVAR par rapport au modèle VAR:

Le modèle SVAR aide à saisir les réponses des variables du système aux chocs structurels identifiés;
Le modèle SVAR grâce à sa décomposition de la variance, permet d'évaluer la part moyenne d’un choc structurel donné dans la dynamique (variation) des variables.

Quelque soit les valeurs des matrices $A$ et $B$, le système résultant contient plus d'équations que d'inconnues etnécessit de faire des restrictions pour être identifiable.

Les paramètres du modèle sont estimés en minimisant la log-vraissemblance négative.

$$lnL_c(A,B) = -  \frac{KT}{2}ln(2\pi) + \frac{T}{2}ln|A|^2 - \frac{T}{2}ln|B|^2 - \frac{T}{2}tr(A^T (B^{-1})^T B^{-1} A \Sigma_u) $$


### 3. Vector error correction models (VECM)

Lorsque les séries ne sont pas stationnaires mais cointégrées, les modèles vectoriels à correction d’erreur (VECM) permettent de spécifier des relations stables à long terme tout en analysant dans le même temps la dynamique de court terme des variables considérées.
 
Partant de l'équation du processus VAR, nous pouvons définir l'équation d'un processus VECM de la manière suivante : 

$$\Delta y_t = \alpha \beta^T y_{t-p} + \Gamma_1 \Delta y_{t-1} + ... + \Gamma_{p-1} y_{t-p+1} + u_t  $$ 
Avec  :

$$\Gamma_i = - (I - A_1 - ... - A_i), \quad i = 1, ..., p-1$$
Et 
$$\Pi = \alpha \beta^T = - (I - A_1 - ... - A_i)$$  

### 4.Structural vector error correction (SVECM)  

#### 4.1 Modèle

En reconsidérerant l'équation précédante du processus VECM. Comme pour le modèle SVAR, on peut appliquer un raisonnement analogue aux modèles SVEC, en particulier lorsque la représentation VAR de niveau équivalent du
Le VECM est utilisé. Toutefois, les informations contenues dans les propriétés de cointégration ne sont donc pas utilisées pour identifier les restrictions sur les chocs structurels. De ce fait, les variables ne sont pas utilisées pour identifier les restrictions aux chocs structurels.


$$\Delta y_t = \alpha \beta^T y_{t-1}  + \Gamma_1 \Delta y_{t-1}+ ... + \Gamma_{p-1} y_{t-p+1} + B \epsilon_t $$

où $u_t = B\epsilon_t$ et $\epsilon_t\sim\mathcal{N}(0, I_K)$

Le processus peut se mettre sous la forme de moyenne mobile comme suit:

$$ y_t = \Xi\sum_{i=1}^tu_i + \sum_{j=0}^\infty\Xi_j^\star u_{t-j} + y_0^\star $$
C'est donc la somme d'une composante intégrée à l'ordre 1 et d'une composante stationaire. $\Xi$ désigne une matrice de rang $K-r$, avec r nombre de relations de cointégration stationaires. 


### 4.2 Implémentation

Pour l'implémentation, les auteurs ont supposé que les rendements d'échelle sont constants et, par conséquent, la productivité n'est déterminée que par les chocs de production. Ils ont également supposé que les chocs de la demande de main-doeuvre n'exercent pas d'effet immédiat sur les salaires réels. Formelement, ils supposent que
$$ \Xi B_{1j} = 0\quad \mathrm{pour} \quad j=1,2,3,4 $$

```{r, message=FALSE, warning=FALSE}

vecm <- ca.jo(Canada[, c("prod", "e", "U", "rw")], type = "trace", ecdet = "trend", K = 3, spec = "transitory")
SR <- matrix(NA, nrow = 4, ncol = 4)
SR[4, 2] <- 0
LR <- matrix(NA, nrow = 4, ncol = 4)
LR[1, 2:4] <- 0
LR[2:4, 4] <- 0
svec <- SVEC(vecm, LR = LR, SR = SR, r = 1, lrtest = FALSE, boot = TRUE, runs = 100)
summary(svec)

```

Les auteurs ont cherché à savoir si les chocs de l'offre de travail n'ont pas d'impact à long terme sur le chômage ($\Xi B_{33}=0$) et effectué un test LR à cet affet.

```{r, message=FALSE, warning=FALSE}
LR[3, 3] <- 0
svec.oi <- update(svec, LR = LR, lrtest = TRUE, boot = FALSE)
svec.oi$LRover

```
L'hypothèse nulle selon laquelle les chocs sur l'offre de travail n'exercent pas un effet à long terme sur le chômage est rejetée pour un niveau de signification de $5\%$.

Afin d'étudier les effets dynamiques sur le chômage, les auteurs ont appliqué une analyse de réponse impulsionnelle. 
```{r,message=FALSE, warning=FALSE}
svec.irf <- irf(svec, response = "U", n.ahead = 48, boot = TRUE)
plot(svec.irf)

```


L'analyse de la réponse impulsionnelle montre les effets des différents chocs, c'est-à-dire la production, la demande de travail, l'offre de travail et le salaire, au chômage.  

# Annexe 
## 1. Test de blancheur (Test de Ljung-Box)
Hypothèses : $$ \begin{array}{l}
H_0 : \forall h \in [|1,...,k|] : \rho(h) = 0\\
H_1 : \forall h \in [|1,...,k|] : \rho(h) \ne 0
    \end{array}$$
La statistique du test est $Q^*_k = T(T+2)\sum^k_{h=1}\frac{\hat{\rho}^2(h)}{T-h}$
    
## 2. Test de Stationnarité :Test augmenté de Dickey-Fuller (ADF)
Hypothèses :  

**H_0 :** Y_t est un processus intégré d'ordre 1 au minimum $\Leftrightarrow$ Présence de racine unitaire (Y_t non stationnaire)  

**H_1 :** Y_t est un processus AR(P) $\Leftrightarrow$ Pas de présence de racine unitaire (Y_t  stationnaire)





